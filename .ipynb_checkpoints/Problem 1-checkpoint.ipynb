{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preped\n"
     ]
    }
   ],
   "source": [
    "#Extract Data\n",
    "import numpy as np\n",
    "import random\n",
    "import copy\n",
    "\n",
    "datasetFile = open('./spambase.data', 'r')\n",
    "\n",
    "spam = list()\n",
    "notSpam = list()\n",
    "\n",
    "\n",
    "for line in datasetFile:\n",
    "    splitedLine = line.split(',')\n",
    "    for a in range(0, len(splitedLine)):\n",
    "        splitedLine[a] = float(splitedLine[a])\n",
    "    if(splitedLine[-1] == 1):\n",
    "        spam.append(splitedLine)\n",
    "    else:\n",
    "        notSpam.append(splitedLine)\n",
    "\n",
    "#Randomize\n",
    "random.shuffle(spam)\n",
    "random.shuffle(notSpam)\n",
    "\n",
    "training = copy.deepcopy(spam[0:1359])\n",
    "\n",
    "notSpamTraining = copy.deepcopy(notSpam[0:2091])\n",
    "training.extend(notSpamTraining)\n",
    "\n",
    "testing = copy.deepcopy(spam[1359:-1])\n",
    "\n",
    "notSpamTesting = copy.deepcopy(notSpam[2091:-1])\n",
    "testing.extend(notSpamTesting)\n",
    "\n",
    "random.shuffle(training)\n",
    "random.shuffle(testing)\n",
    "\n",
    "trainingX = list()\n",
    "trainingY = list()\n",
    "for row in training:\n",
    "    trainingX.append(row[:-1])\n",
    "    trainingY.append(row[-1])\n",
    "trainingX = np.array(trainingX)\n",
    "\n",
    "\n",
    "trainingY = np.array(trainingY)\n",
    "    \n",
    "trainingX = np.array([row[:-1] for row in training])\n",
    "trainingY = np.array([row[-1] for row in training])\n",
    "\n",
    "testingX = np.array([row[:-1] for row in testing])\n",
    "testingY = np.array([row[-1] for row in testing])\n",
    "\n",
    "print(\"Data Preped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with 10\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'traininggX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-a4c767aaa932>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Random Forest with %d\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnumOfTrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m#Metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraininggX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mconfMatrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainingY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mconfMatrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mconfMatrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'traininggX' is not defined"
     ]
    }
   ],
   "source": [
    "#Sklearn's Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics \n",
    "\n",
    "for numOfTrees in [10, 50 ,100]:\n",
    "    clf = RandomForestClassifier(n_estimators=numOfTrees)\n",
    "    clf = clf.fit(trainingX, trainingY)\n",
    "\n",
    "    print(\"Random Forest with %d\" % numOfTrees)\n",
    "    #Metrics\n",
    "    y_pred = clf.predict(trainingX)\n",
    "    confMatrix = metrics.confusion_matrix(trainingY, y_pred)\n",
    "    accuracy = (confMatrix[1][1]+confMatrix[0][0])/len(y_pred)\n",
    "    precision = confMatrix[1][1]/(confMatrix[1][1]+confMatrix[0][1])\n",
    "    recall = confMatrix[1][1]/(confMatrix[1][1]+confMatrix[1][0])\n",
    "    print(\"For training set\")\n",
    "    print(\"Accuracy %.2f\" % accuracy)\n",
    "    print(\"Error %.2f\" % (1-accuracy))\n",
    "    print(\"Precision: %.2f\" % precision)\n",
    "    print(\"Recall: %.2f\" % recall)\n",
    "    print()\n",
    "\n",
    "\n",
    "    y_pred = clf.predict(testingX)\n",
    "    confMatrix = metrics.confusion_matrix(testingY, y_pred)\n",
    "    accuracy = (confMatrix[1][1]+confMatrix[0][0])/len(y_pred)\n",
    "    precision = confMatrix[1][1]/(confMatrix[1][1]+confMatrix[0][1])\n",
    "    recall = confMatrix[1][1]/(confMatrix[1][1]+confMatrix[1][0])\n",
    "    print(\"For testing set\")\n",
    "    print(\"Accuracy %.2f\" % accuracy)\n",
    "    print(\"Error %.2f\" % (1-accuracy))\n",
    "    print(\"Precision: %.2f\" % precision)\n",
    "    print(\"Recall: %.2f\" % recall)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Problem 1 [Random Forest classifier] - 38 points\n",
    "Use the SPAMBASE dataset for this problem. Split the original data into 75% for training and 25% for\n",
    "testing (chosen at random).\n",
    "(a) Use an existing package to train a Random Forest classifier on the training set. Report accuracy, error,\n",
    "precision, and recall on both training and testing sets.\n",
    "(b) Implement your own Random Forest algorithm. The Random Forest training procedure takes as input\n",
    "the training dataset, the number of trees, and the number of features m ≤ d considered at every split\n",
    "(d is the total number of features in the dataset).\n",
    "1\n",
    "(c) Vary the number of features m selected at random at each split. Consider m = d, m = d/2, and\n",
    "m =\n",
    "√\n",
    "d. Report accuracy, error, precision, and recall on the training and testing set.\n",
    "(d) Fix the number of features m =\n",
    "√\n",
    "d. Compare your implementation with the package results for\n",
    "different number of trees (10, 50, and 100)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
