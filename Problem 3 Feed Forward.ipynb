{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Testing data prepped\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.datasets import mnist\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
    "\n",
    "#Format training data\n",
    "trainX = np.reshape(trainX, (-1, 28*28))\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "trainY = trainY.reshape(len(trainY), 1)\n",
    "trainY = onehot_encoder.fit_transform(trainY)\n",
    "\n",
    "#Format testing data\n",
    "testX = np.reshape(testX, (-1, 28*28))\n",
    "\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "testY = testY.reshape(len(testY), 1)\n",
    "testY = onehot_encoder.fit_transform(testY)\n",
    "\n",
    "print(\"Training and Testing data prepped\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 24s 403us/step - loss: 1.3704 - acc: 0.9145\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 25s 420us/step - loss: 1.3455 - acc: 0.9164\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 27s 446us/step - loss: 1.3417 - acc: 0.9167\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 25s 412us/step - loss: 1.3390 - acc: 0.91690s - loss: 1.3399\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 21s 349us/step - loss: 1.3371 - acc: 0.9170\n",
      "60000/60000 [==============================] - 4s 74us/step\n",
      "For train data\n",
      "\n",
      "acc: 91.86%\n",
      "10000/10000 [==============================] - 1s 69us/step\n",
      "For test data\n",
      "\n",
      "acc: 91.93%\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(28*14, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(28, activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainX, trainY, epochs=5, batch_size=32)\n",
    "\n",
    "scores = model.evaluate(trainX, trainY)\n",
    "print(\"For train data\")\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "scores = model.evaluate(testX, testY)\n",
    "print(\"For test data\")\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 20s 339us/step - loss: 0.1361 - acc: 0.9563\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 21s 345us/step - loss: 0.0558 - acc: 0.9834\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 0.0478 - acc: 0.9846\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 0.0435 - acc: 0.9858\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 22s 373us/step - loss: 0.0407 - acc: 0.9864\n",
      "60000/60000 [==============================] - 5s 88us/step\n",
      "For train data\n",
      "\n",
      "acc: 98.64%\n",
      "10000/10000 [==============================] - 1s 92us/step\n",
      "For test data\n",
      "\n",
      "acc: 98.68%\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(28*14, input_dim=28*28, activation='sigmoid'))\n",
    "model.add(Dense(28, activation='sigmoid'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainX, trainY, epochs=5, batch_size=32)\n",
    "\n",
    "scores = model.evaluate(trainX, trainY)\n",
    "print(\"For train data\")\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "scores = model.evaluate(testX, testY)\n",
    "print(\"For test data\")\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.8652 - acc: 0.9399\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0751 - acc: 0.9829\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.0334 - acc: 0.9897\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 110us/step - loss: 0.0269 - acc: 0.9916\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0226 - acc: 0.9927\n",
      "60000/60000 [==============================] - 3s 43us/step\n",
      "For train data\n",
      "\n",
      "acc: 99.40%\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "For test data\n",
      "\n",
      "acc: 99.22%\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(96, input_dim=28*28, activation='relu'))\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dense(28, activation='relu'))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainX, trainY, epochs=5, batch_size=32)\n",
    "\n",
    "scores = model.evaluate(trainX, trainY)\n",
    "print(\"For train data\")\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "scores = model.evaluate(testX, testY)\n",
    "print(\"For test data\")\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
